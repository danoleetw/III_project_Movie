{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Oct 17 14:23:42 2016\n",
    "ver 1.0.4 : 完整版，以佩琳所做之電影總表CSV檔，抓取公用電腦裡已下載之開眼網站單部電影頁面資訊，寫成Json檔傳進MongoDB\n",
    "@author: dano\n",
    "\n",
    "\"\"\"\n",
    "import requests as r\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pymongo\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "#/////////////////////------------------------------------------/////////////////////\n",
    "def atmoviesFile_crawler(file_id):\n",
    "    #設Json檔\n",
    "    a_with_t_movie = {\n",
    "                        'title_c' : '',         #    title_c : 大陸片名\n",
    "                        'title_e' : '',         #    title_e : 英文片名\n",
    "                        'title_t' : '',         #    title_t : 台灣片名\n",
    "                        'atmovie_id' : '',      #    atmovie_id : 開眼id\n",
    "                        'poster' : '',          #    poster : 海報\n",
    "                        'rating' : '',          #    rating : 總評分\n",
    "                        'intro_s' : '',         #    intro_s : 短簡介\n",
    "                        'runtime' : '',         #    runtime : 片長\n",
    "                        'release_date' : '',    #    release_date : 上映時間\n",
    "                        'box' : '',             #    box : 票房\n",
    "                        'intro_l' : '',         #    intro_l : 長簡介\n",
    "                        'youtube' : [],         #    youtube : 預告片\n",
    "                        'picture' : '',         #    picture : 劇照\n",
    "                        'news' : '',            #    news : 更多新聞按鈕的href\n",
    "                        'director' : [],        #    director : [導演]\n",
    "                        'actor' : [],           #    actor : [演員]\n",
    "                        'writer' : [],          #    writer : [編劇]\n",
    "                        'year' : '',            #    year : 影片年份\n",
    "                        'area' : '',            #    area : 出品國\n",
    "                        'publisher' : '',       #    publisher : 發行商\n",
    "                        'issuer' : '',          #    issuer : 出品\n",
    "                        'language' : '',        #    language : 語言\n",
    "                        'official' : '',        #    official : 官網\n",
    "                        'imdb' : '',            #    imdb : IMDb網址\n",
    "                        'update' : '',          #    update : 更新時間\n",
    "                        'type' : [] ,           #    type : 類型\n",
    "                        'url' : ''              #    url : 網址\n",
    "                        }\n",
    "    #//////////////------------------------------------------//////////////\n",
    "    #抓取頁面並soup(因之前已先下載開眼的各電影網頁存於公用電腦裡，故本程式是以開檔案方式運行)\n",
    "    filename_head = r'\\\\10.120.28.17\\movie\\atmovies\\atmovie_html'\n",
    "    filename = filename_head + '\\\\' + file_id + '.html' \n",
    "    f = open(filename,'r')\n",
    "    soup = BeautifulSoup(f, 'lxml')\n",
    "    error_utf8 ='伺服器錯誤'.decode(\"utf8\")\n",
    "    f.close()\n",
    "    if re.search(error_utf8,soup.text):\n",
    "        with open(r'\\\\10.120.28.17\\movie\\atmovies\\error_list.csv','a') as error_list:\n",
    "            error_list.write(file_id)\n",
    "            error_list.write('\\n')\n",
    "            print \"error\"\n",
    "    else:\n",
    "        #先抓內容        \n",
    "        div_list = soup.find('div',class_=\"content content-left\")\n",
    "        filmTagBlock = div_list.find('div', id=\"filmTagBlock\")\n",
    "        \n",
    "        runtime_class = filmTagBlock.find('ul', class_=\"runtime\")\n",
    "        filmTagBlock_lis = runtime_class.find_all('li')\n",
    "        colon_utf8 = '：'.decode(\"utf8\")\n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #片名    \n",
    "        a_with_t_movie['title_t'] = div_list.find('div', class_=\"filmTitle\").text.split(' ')[0].strip()\n",
    "#        print 'title_t:' + a_with_t_movie['title_t']\n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #開眼id\n",
    "        a_with_t_movie['atmovie_id'] = file_id\n",
    "#        print 'atmovie_id:' + a_with_t_movie['atmovie_id']\n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #海報\n",
    "        posterLink = filmTagBlock.find('img')['src']\n",
    "        a_with_t_movie['poster'] = posterLink\n",
    "#        print 'poster:' + a_with_t_movie['poster']\n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #轉往開眼評分網頁取得評分並存檔    \n",
    "        ratingLink = soup.find('iframe')['src']\n",
    "        headers = {\n",
    "                    \n",
    "                    'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36',\n",
    "                  }            \n",
    "        res_rating = r.get(ratingLink, headers=headers)\n",
    "        soup_rating = BeautifulSoup(res_rating.text, 'lxml')\n",
    "        if soup_rating.find(class_='thisRating'):\n",
    "            rating_id =  filename_head + '\\\\Ratings\\\\' + file_id +'.html'\n",
    "            f_rating = open(rating_id, 'w')\n",
    "            f_rating.write(res_rating.content)\n",
    "            f_rating.close()\n",
    "            point = soup_rating.find(class_='thisRating')\n",
    "            a_with_t_movie['rating'] = point.text\n",
    "#            print 'rating:' + a_with_t_movie['rating']\n",
    "        else:\n",
    "            a_with_t_movie['rating'] = 'null'\n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #短簡介            \n",
    "        span_list = filmTagBlock.find_all('span')\n",
    "        if span_list[2]:\n",
    "            intro_s = span_list[2]\n",
    "            a_with_t_movie['intro_s'] = intro_s.text.split('\\n')[1].strip()\n",
    "        else:\n",
    "            a_with_t_movie['intro_s'] = 'null'\n",
    "#        print 'intro_s:' + a_with_t_movie['intro_s']\n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #片長    \n",
    "        runtim_utf8 = '片長'.decode(\"utf8\")\n",
    "        if re.search(runtim_utf8,filmTagBlock.text):\n",
    "            for li in filmTagBlock_lis:\n",
    "                if re.search(runtim_utf8,li.text):\n",
    "                    a_with_t_movie['runtime'] = li.text.split(colon_utf8)[1]\n",
    "                else:\n",
    "                    a_with_t_movie['runtime'] = 'null'\n",
    "#               print 'runtime:' + a_with_t_movie['runtime']\n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #上映時間\n",
    "        date_utf8 = '上映日期'.decode(\"utf8\")\n",
    "        if re.search(date_utf8,filmTagBlock.text):\n",
    "            for li in filmTagBlock_lis:\n",
    "                if re.search(date_utf8,li.text):\n",
    "                    a_with_t_movie['release_date'] = li.text.split(colon_utf8)[1]\n",
    "                else:\n",
    "                    a_with_t_movie['release_date'] = 'null'\n",
    "#               print 'release_date:' + a_with_t_movie['release_date']\n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #票房\n",
    "        box_utf8 = '票房'.decode(\"utf8\")\n",
    "        if re.search(box_utf8,filmTagBlock.text):\n",
    "            for li in filmTagBlock_lis:\n",
    "                if re.search(box_utf8,li.text):\n",
    "                    a_with_t_movie['box'] = li.text.split(colon_utf8)[1]  \n",
    "                else:\n",
    "                    a_with_t_movie['box'] = 'null'\n",
    "#            print 'box:' + a_with_t_movie['box']\n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #長簡介\n",
    "        a_with_t_movie['intro_l'] = soup.find('div',id='googleAD').find_next_sibling().text.strip()\n",
    "#        print 'intro_l:' + a_with_t_movie['intro_l']\n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #預告片\n",
    "        if div_list.find('div',class_='video_view'):\n",
    "            video_view = div_list.find('div',class_='video_view')\n",
    "            video_more = 'filmMoreTrailer'\n",
    "            if re.search(video_more, video_view.__str__()): \n",
    "                url_video = r'http://app2.atmovies.com.tw/filmMoreTrailer/' + file_id\n",
    "                res_video = r.get(url_video, headers=headers)\n",
    "                res_video.encoding = 'utf-8'\n",
    "                soup_video = BeautifulSoup(res_video.text, 'lxml')\n",
    "                video_iframe = soup_video.find_all('iframe', class_='image featured')\n",
    "                for iframe in video_iframe:\n",
    "                    a_with_t_movie['youtube'].append(iframe['src'])\n",
    "            else:\n",
    "                a_with_t_movie['youtube'] = div_list.find('iframe',class_='image featured')['src']\n",
    "#        print a_with_t_movie['youtube']\n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #劇照\n",
    "        if div_list.find('a', alt='劇～照'):\n",
    "            a_with_t_movie['picture'] = div_list.find('a', alt='劇～照')['href']\n",
    "        else:\n",
    "            a_with_t_movie['picture'] = 'null'\n",
    "#        print 'picture:' + a_with_t_movie['picture']\n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #更多新聞按鈕的href\n",
    "        if div_list.find('a', alt=\"更多影片相關新聞\"):\n",
    "            a_with_t_movie['news'] = div_list.find('a', alt=\"更多影片相關新聞\")['href']\n",
    "        else:\n",
    "            a_with_t_movie['news'] = 'null'\n",
    "#       print 'news:' + a_with_t_movie['news']\n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #抓電影基本資料\n",
    "        if div_list.find('div',id='filmCastDataBlock'):\n",
    "            datas = div_list.find('div',id='filmCastDataBlock').find_all('ul')\n",
    "            director_utf8 = \"導演\".decode(\"utf8\")\n",
    "            arctor_utf8 = \"演員\".decode(\"utf8\")\n",
    "            writer_utf8 = \"編劇\".decode(\"utf8\")\n",
    "            #先確認連結導演編劇演員的more網頁是否存在\n",
    "            if  datas[0].find('a', alt='更多'):\n",
    "                #如果存在，代表此處有兩個'ul'，第一個是演員表，另一個是電影資料\n",
    "                datas_url = datas[0].find('a', alt='更多')['href']\n",
    "                datas_block = datas[1].find_all('li')\n",
    "                #//////////////------------------------------------------//////////////\n",
    "                #超連結出去抓導演編劇演員(本段由佩琳獨家贊助播出)\n",
    "                def cast_soup(datas_url): # 參數給cast頁的url，return[li標籤們(演員表的每一行)]\n",
    "                    res = r.get(datas_url, headers=headers)\n",
    "                    res.encoding = 'utf-8'\n",
    "                    #為避免發生評分網頁不能連了問題，因此存取職務網頁\n",
    "                    cast_id =  filename_head + '\\\\Casts\\\\' + file_id +'.html'\n",
    "                    f = open(cast_id, 'w')\n",
    "                    f.write(res.content)\n",
    "                    f.close()            \n",
    "                    \n",
    "                    soup = BeautifulSoup(res.text, 'lxml')\n",
    "                    content = soup.select('div.important(mobile) div li')\n",
    "                    return  content\n",
    "                def staff(dict_key, keyword_utf8, cast): # dict_key=要回傳的{}總表用的key值, keyword_utf8=要搜尋的字，中文需decode(), cast=cast_soup(url)\n",
    "                    match = 'no' # re.search成功=yes, 不成功=no\n",
    "                    value_list  = []\n",
    "                    for li_tag in cast:\n",
    "                        if re.search(keyword_utf8,li_tag.text):\n",
    "                            match = 'yes' # re.search成功\n",
    "                        elif match == 'yes' and li_tag.a:\n",
    "                            value_list .append(li_tag.a.text.strip()) #把工作人員加到list\n",
    "                        else:\n",
    "                            match = 'no' # re.search失敗\n",
    "                            pass\n",
    "                    return {dict_key : value_list } #回傳{'職務(呼叫函數時要給參數)': ['工作人員']}\n",
    "                def staff_all(cast): # 參數給cast=cast_soup(url), return全部工作人員表 (此函數備用)\n",
    "                    final_list = []\n",
    "                    stuff_list = []\n",
    "                    dict = {}\n",
    "                    director = \"yes\"\n",
    "                    job = ''\n",
    "                    for tag in cast:\n",
    "                        if director == \"yes\": # 條件True,強制把第一行的導演load進來\n",
    "                            job = tag.text.split(colon_utf8)[0] # 把職務存進參數job\n",
    "                            director = \"no\" # 把條件改成False\n",
    "                        elif tag.a: # 工作人員會有a標籤\n",
    "                            stuff_list.append(tag.a.text) # 把工作人員加到stuff_list\n",
    "                        else: # 職務名稱沒有a標籤\n",
    "                            dict[job] = stuff_list \n",
    "                            final_list.append(dict) # 把以上的{職務:[stuff_list]}加進final_list\n",
    "                            job = tag.text.split(colon_utf8)[0] # 以下開始新的任務，把職務存進參數job\n",
    "                            stuff_list = [] # 重置\n",
    "                            dict = {} # 重置\n",
    "                            dict[job] = stuff_list  # 重置            \n",
    "                        final_list.append(dict) # 把最後一個{職務:[stuff_list]}加進final_list\n",
    "                    return final_list\n",
    "                # main\n",
    "                cast = cast_soup(datas_url) \n",
    "                #//////////////------------------------------------------//////////////\n",
    "                #導演\n",
    "                a_with_t_movie['director'] = staff('director', director_utf8, cast)['director']\n",
    "    #            print a_with_t_movie['director']\n",
    "                #演員\n",
    "                a_with_t_movie['actor'] = staff('arctor', arctor_utf8, cast)['arctor']\n",
    "    #            print a_with_t_movie['actor']\n",
    "                #編劇\n",
    "                a_with_t_movie['writer'] = staff('writer', writer_utf8, cast)['writer']\n",
    "    #            print a_with_t_movie['writer']\n",
    "            else:\n",
    "                datas_block = datas[0].find_all('li')\n",
    "                a_with_t_movie['director'] = 'null'\n",
    "    #            print a_with_t_movie['director']\n",
    "                #演員\n",
    "                a_with_t_movie['actor'] = 'null'\n",
    "    #           print a_with_t_movie['actor']\n",
    "                #編劇\n",
    "                a_with_t_movie['writer'] = 'null'\n",
    "    #            print 'writer' + a_with_t_movie['writer']\n",
    "            \n",
    "            #//////////////------------------------------------------//////////////\n",
    "            #抓出版基本資料\n",
    "            year_utf8 = \"份：\".decode(\"utf8\")\n",
    "            area_utf8 = \"國：\".decode(\"utf8\")\n",
    "            publisher_utf8 = \"商：\".decode(\"utf8\")\n",
    "            issuer_utf8 = \"品：\".decode(\"utf8\")\n",
    "            language_utf8 = \"言：\".decode(\"utf8\")\n",
    "            official_utf8 = \"官方網站\".decode(\"utf8\")\n",
    "            \n",
    "            #搜尋每個'li'看是否有該文字，有該文字再加入\n",
    "            for li in datas_block:\n",
    "                #影片年份\n",
    "                if re.search(year_utf8,li.text):\n",
    "                    a_with_t_movie['year'] = li.text.split(colon_utf8)[1].strip()\n",
    "#                print 'year:' + a_with_t_movie['year']\n",
    "                #出品國\n",
    "                if re.search(area_utf8,li.text):\n",
    "                    a_with_t_movie['area'] = li.text.split(colon_utf8)[1].strip()\n",
    "#                print 'area:' + a_with_t_movie['area']\n",
    "                #發行商\n",
    "                if re.search(publisher_utf8,li.text):\n",
    "                    a_with_t_movie['publisher'] = li.text.split(colon_utf8)[1].strip()\n",
    "#                print 'publisher:' + a_with_t_movie['publisher']\n",
    "                #出品\n",
    "                if re.search(issuer_utf8,li.text):\n",
    "                    a_with_t_movie['issuer'] = li.text.split(colon_utf8)[1].strip()\n",
    "#                print 'issuer:' + a_with_t_movie['issuer']\n",
    "                #語言\n",
    "                if re.search(language_utf8,li.text):\n",
    "                    a_with_t_movie['language'] = li.text.split(colon_utf8)[1].strip()\n",
    "#                print 'language:' + a_with_t_movie['language']\n",
    "                #官網\n",
    "                if re.search(official_utf8,li.text):\n",
    "                    a_with_t_movie['official'] = li.a['href']\n",
    "#                print 'official:' + a_with_t_movie['official']\n",
    "                #IMDb網址\n",
    "                if re.search('IMDb',li.text):\n",
    "                    a_with_t_movie['imdb'] = li.a['href']\n",
    "#                print 'imdb:' + a_with_t_movie['imdb']\n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #更新時間\n",
    "        updateTime = div_list.find('div', class_='updateTime')\n",
    "        a_with_t_movie['update'] = updateTime.text.split(colon_utf8)[1].strip()\n",
    "#        print 'update:' + a_with_t_movie['update']\n",
    "        #類型(由岳峰處理)\n",
    "        #a_with_t_movie['type'] =   \n",
    "        #//////////////------------------------------------------//////////////\n",
    "        #寫入MongoDB\n",
    "        client = pymongo.MongoClient('10.120.28.17',27018)\n",
    "        db = client.atmovie\n",
    "        collect = db.atmovieFilm\n",
    "        collect.insert_one(a_with_t_movie)\n",
    "    \n",
    "\n",
    "\n",
    "#MAIN:匯入佩琳的清單\n",
    "listFile = open(r'\\\\10.120.28.17\\movie\\atmovies\\all_movie_1024.csv','r')\n",
    "with listFile as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    rows = [row[1] for row in reader]\n",
    "listFile.close()\n",
    "\n",
    "for row in rows:\n",
    "    time.sleep(1)\n",
    "    start = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    starttime = datetime.datetime.now()\n",
    "    print row\n",
    "    atmoviesFile_crawler(row)\n",
    "    endtime = datetime.datetime.now()\n",
    "    time_data = row + ',' + start + ',' + str((endtime - starttime).microseconds)\n",
    "    f_d = open('atmovie_log.csv','a')\n",
    "    f_d.write(time_data)\n",
    "    f_d.write('\\n')\n",
    "    f_d.close()\n",
    "\n",
    "#單頁測試用\n",
    "#row = 'fcus62103167'\n",
    "#print row\n",
    "#atmoviesFile_crawler(row)\n",
    " \n",
    "print \"-------------------完成啦!!!thank god!!!---------------\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
